{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Для запуска с ВМ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from docker_init import run_init\n",
    "\n",
    "_ = run_init(local=False) # только экспорт конфигов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% env HADOOP_HOME=/usr/local/hadoop\n",
    "% env CONF_DIR=/usr/local/hadoop/etc/hadoop\n",
    "% env WORK_DIR=/home/jovyan/work\n",
    "% env MAPPER=/home/jovyan/work/mapper.py\n",
    "% env REDUCER=/home/jovyan/work/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить данные в HDFS\n",
    "! hadoop fs -put spotify/log_mini.csv /tmp/spotify_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hadoop fs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod +x $MAPPER\n",
    "! chmod +x $REDUCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -rm -r /tmp/spotify_results\n",
    "\n",
    "# Стрим-вычисление прослушиваний с использованием Hadoop Streaming\n",
    "! hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.4.jar \\\n",
    "  -input /tmp/spotify_data.csv \\\n",
    "  -output /tmp/spotify_results \\\n",
    "  -mapper $MAPPER \\\n",
    "  -reducer $REDUCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -ls /tmp/spotify_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv = f\"{os.getenv('WORK_DIR')}/mapreduce_results.csv\"\n",
    "\n",
    "if os.path.exists(result_csv):\n",
    "    os.remove(result_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать пустой .csv\n",
    "\n",
    "with open(result_csv, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавить названия столбцов\n",
    "! echo \"track_id,count\" > $WORK_DIR/mapreduce_results.csv # Добавляем заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить файл с результатами из HDFS\n",
    "! hadoop fs -cat /tmp/spotify_results/part-00000 | \\\n",
    "  awk '{print $1 \",\" $2}' | \\\n",
    "  sort -t, -k2 -nr \\\n",
    "  >> $WORK_DIR/mapreduce_results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(result_csv)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
