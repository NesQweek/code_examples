{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3),\n",
    "                        pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество изображений: 8677\n"
     ]
    }
   ],
   "source": [
    "EXTENSIONS = {'.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG'}\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    return [os.path.join(root, filename)\n",
    "            for root, _, filenames in os.walk(root_dir)\n",
    "            for filename in filenames\n",
    "            if any(filename.endswith(ext) for ext in EXTENSIONS)\n",
    "            if os.path.exists(os.path.join(root, filename))]\n",
    "\n",
    "\n",
    "ROOT_DIR = './datasets/caltech101'\n",
    "filenames = sorted(get_file_list(ROOT_DIR))\n",
    "print('Количество изображений:', len(filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8677 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE партия изображений для одновременного извлечения признаков\n",
    "# datagen предобрабатывает (в т.ч. нормализует) изображения перед подачей в модель\n",
    "# generator генератор данных, который будет загружать изображения из директории root_dir\n",
    "## Параметр class_mode=None означает, что мы не используем информацию о классах изображений, \n",
    "## а просто извлекаем признаки. shuffle=False означает, что порядок изображений не будет перемешиваться\n",
    "## для того чтобы сохранить соответствие между изображениями и их признаками\n",
    "# NUM_IMAGES общее количество изображений в наборе данных\n",
    "# NUM_EPOCHS количество итераций, необходимых для обработки всех изображений, учитывая BATCH_SIZE\n",
    "# feature_list модель использует generator для извлечения признаков из всех изображений и сохраняет в список\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    BATCH_SIZE = 128\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    generator = datagen.flow_from_directory(ROOT_DIR,\n",
    "                                            target_size=(224, 224),\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "\n",
    "    NUM_IMAGES = len(generator.filenames)\n",
    "    NUM_EPOCHS = int(math.ceil(NUM_IMAGES / BATCH_SIZE))\n",
    "\n",
    "    start_time = time.time()\n",
    "    feature_list = []\n",
    "    feature_list = MODEL.predict(generator, NUM_EPOCHS)\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images   =  8677\n",
      "Shape of feature_list =  (8677, 2048)\n",
      "Time taken in sec =  26.67900013923645\n"
     ]
    }
   ],
   "source": [
    "for i, features in enumerate(feature_list):\n",
    "    feature_list[i] = features / norm(features)\n",
    "\n",
    "feature_list = feature_list.reshape(len(feature_list), -1)\n",
    "\n",
    "print(\"Num images   = \", len(generator.classes))\n",
    "print(\"Shape of feature_list = \", feature_list.shape)\n",
    "print(\"Time taken in sec = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [ROOT_DIR + '/' + s for s in generator.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(generator.classes, open('./data/class_ids-caltech101.pickle',\n",
    "                                    'wb'))\n",
    "pickle.dump(filenames, open('./data/filenames-caltech101.pickle', 'wb'))\n",
    "pickle.dump(\n",
    "    feature_list,\n",
    "    open('./data/features-caltech101-' + MODEL.name + '.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
