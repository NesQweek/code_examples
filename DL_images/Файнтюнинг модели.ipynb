{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from get_less_acc_classes import get_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка класс-идентификаторов\n",
    "with open('./data/class_ids-caltech101.pickle', 'rb') as f:\n",
    "    class_ids = pickle.load(f)\n",
    "\n",
    "# Загрузка списка имен файлов\n",
    "with open('./data/filenames-caltech101.pickle', 'rb') as f:\n",
    "    filenames = pickle.load(f)\n",
    "\n",
    "# Загрузка списка признаков\n",
    "with open('./data/features-caltech101-' + 'resnet50' + '.pickle', 'rb') as f:\n",
    "    features = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLES = 8677\n",
    "NUM_CLASSES = 101\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "PATIENCE = 5  # Количество эпох для ранней остановки\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "ROOT_DIR = './datasets/caltech101'\n",
    "base_model = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my\\DL\\CV\\chapter-2\\.conda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая точность классификации: 91.53%\n",
      "\tbonsai: 97.56%\n",
      "\tFaces_easy: 96.70%\n",
      "\tbrain: 95.45%\n",
      "\tbutterfly: 95.24%\n",
      "\tewer: 95.24%\n",
      "\tcougar_face: 94.74%\n",
      "\tgrand_piano: 94.44%\n",
      "\tllama: 94.12%\n",
      "\tnautilus: 94.12%\n",
      "\tcup: 93.75%\n",
      "\telephant: 93.75%\n",
      "\tlamp: 93.33%\n",
      "\tlotus: 93.33%\n",
      "\ttick: 92.31%\n",
      "\tchair: 91.67%\n",
      "\tsea_horse: 91.67%\n",
      "\tcrocodile_head: 90.91%\n",
      "\tcougar_body: 90.00%\n",
      "\tdolphin: 90.00%\n",
      "\temu: 90.00%\n",
      "\tflamingo: 88.89%\n",
      "\tmetronome: 88.89%\n",
      "\thelicopter: 88.24%\n",
      "\tyin_yang: 87.50%\n",
      "\telectric_guitar: 86.67%\n",
      "\twindsor_chair: 86.67%\n",
      "\tinline_skate: 85.71%\n",
      "\tscissors: 85.71%\n",
      "\tdollar_bill: 84.62%\n",
      "\tstapler: 84.62%\n",
      "\tgerenuk: 83.33%\n",
      "\tpyramid: 83.33%\n",
      "\tsnoopy: 83.33%\n",
      "\tstrawberry: 83.33%\n",
      "\tstegosaurus: 78.57%\n",
      "\tumbrella: 77.78%\n",
      "\tcannon: 75.00%\n",
      "\tokapi: 75.00%\n",
      "\tgramophone: 73.33%\n",
      "\tcrayfish: 72.73%\n",
      "\tbeaver: 66.67%\n",
      "\tceiling_fan: 62.50%\n",
      "\tflamingo_head: 62.50%\n",
      "\tmayfly: 62.50%\n",
      "\tschooner: 62.50%\n",
      "\tant: 60.00%\n",
      "\tbarrel: 57.14%\n",
      "\tbass: 54.55%\n",
      "\tbrontosaurus: 50.00%\n",
      "\twrench: 44.44%\n",
      "\toctopus: 42.86%\n",
      "\tcrocodile: 37.50%\n",
      "\tlobster: 33.33%\n",
      "\twheelchair: 31.25%\n",
      "\tplatypus: 25.00%\n",
      "\tmandolin: 14.29%\n",
      "\tanchor: 0.00%\n",
      "\twater_lilly: 0.00%\n",
      "\twild_cat: 0.00%\n"
     ]
    }
   ],
   "source": [
    "less_accurate_classnames = get_classes(\n",
    "ROOT_DIR,\n",
    "'data/filenames-caltech101.pickle',\n",
    "'data/features-caltech101-resnet50.pickle',\n",
    "'data/class_ids-caltech101.pickle'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Копирование папки './datasets/caltech101' в augmented_data успешно завершено.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('augmented_data'):\n",
    "    shutil.rmtree('augmented_data')\n",
    "\n",
    "# Копируем содержимое папки\n",
    "shutil.copytree(ROOT_DIR, 'augmented_data')\n",
    "print(f\"Копирование папки '{ROOT_DIR}' в augmented_data успешно завершено.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_increment(accuracy):\n",
    "    if 70 <= accuracy < 100:\n",
    "        return 2\n",
    "    elif 50 <= accuracy < 70:\n",
    "        return 3\n",
    "    elif 30 <= accuracy < 50:\n",
    "        return 4\n",
    "    elif 5 <= accuracy < 30:\n",
    "        return 5\n",
    "    else:\n",
    "        return 1  # По умолчанию генерировать 1 копию\n",
    "\n",
    "for class_name, accuracy in less_accurate_classnames.items():\n",
    "    images_increment = get_images_increment(accuracy)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    class_dir = os.path.join(ROOT_DIR, class_name)\n",
    "    class_images = os.listdir(class_dir)\n",
    "\n",
    "    for img_name in class_images:\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        \n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=os.path.join('augmented_data', class_name), save_prefix=class_name, save_format='jpg'):\n",
    "            i += 1\n",
    "            if i >= images_increment:  # Аугментация n копий для каждого изображения\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   validation_split=0.2  # 20% данных для валидации\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13551 images belonging to 101 classes.\n",
      "Found 3331 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'augmented_data',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=12345,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'augmented_data',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.experimental.set_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.2)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPU cores: 12\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f\"Number of available CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "106/106 [==============================] - 40s 285ms/step - loss: 2.4853 - acc: 0.4542 - val_loss: 1.0487 - val_acc: 0.7655\n",
      "Epoch 2/30\n",
      "106/106 [==============================] - 35s 306ms/step - loss: 0.9963 - acc: 0.7514 - val_loss: 0.5509 - val_acc: 0.8718\n",
      "Epoch 3/30\n",
      "106/106 [==============================] - 35s 310ms/step - loss: 0.6875 - acc: 0.8154 - val_loss: 0.4003 - val_acc: 0.9030\n",
      "Epoch 4/30\n",
      "106/106 [==============================] - 35s 305ms/step - loss: 0.5313 - acc: 0.8526 - val_loss: 0.3547 - val_acc: 0.9024\n",
      "Epoch 5/30\n",
      "106/106 [==============================] - 35s 307ms/step - loss: 0.4495 - acc: 0.8711 - val_loss: 0.3189 - val_acc: 0.9114\n",
      "Epoch 6/30\n",
      "106/106 [==============================] - 35s 308ms/step - loss: 0.3958 - acc: 0.8861 - val_loss: 0.2734 - val_acc: 0.9270\n",
      "Epoch 7/30\n",
      "106/106 [==============================] - 88s 816ms/step - loss: 0.3574 - acc: 0.8963 - val_loss: 0.2468 - val_acc: 0.9289\n",
      "Epoch 8/30\n",
      "106/106 [==============================] - 34s 303ms/step - loss: 0.3175 - acc: 0.9081 - val_loss: 0.2232 - val_acc: 0.9358\n",
      "Epoch 9/30\n",
      "106/106 [==============================] - 35s 308ms/step - loss: 0.3013 - acc: 0.9076 - val_loss: 0.2234 - val_acc: 0.9385\n",
      "Epoch 10/30\n",
      "106/106 [==============================] - 35s 307ms/step - loss: 0.2710 - acc: 0.9208 - val_loss: 0.2084 - val_acc: 0.9334\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - 35s 309ms/step - loss: 0.2517 - acc: 0.9244 - val_loss: 0.1971 - val_acc: 0.9445\n",
      "Epoch 12/30\n",
      "106/106 [==============================] - 84s 773ms/step - loss: 0.2376 - acc: 0.9283 - val_loss: 0.1833 - val_acc: 0.9481\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 49s 421ms/step - loss: 0.2208 - acc: 0.9322 - val_loss: 0.1747 - val_acc: 0.9508\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 34s 304ms/step - loss: 0.2074 - acc: 0.9371 - val_loss: 0.1675 - val_acc: 0.9508\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 35s 312ms/step - loss: 0.1941 - acc: 0.9408 - val_loss: 0.1631 - val_acc: 0.9535\n",
      "Epoch 16/30\n",
      "106/106 [==============================] - 35s 305ms/step - loss: 0.1889 - acc: 0.9424 - val_loss: 0.1523 - val_acc: 0.9523\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 35s 305ms/step - loss: 0.1760 - acc: 0.9468 - val_loss: 0.1720 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 35s 308ms/step - loss: 0.1749 - acc: 0.9464 - val_loss: 0.1711 - val_acc: 0.9478\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 35s 306ms/step - loss: 0.1725 - acc: 0.9444 - val_loss: 0.1511 - val_acc: 0.9520\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 35s 308ms/step - loss: 0.1636 - acc: 0.9504 - val_loss: 0.1554 - val_acc: 0.9541\n",
      "Epoch 21/30\n",
      "106/106 [==============================] - 35s 306ms/step - loss: 0.1531 - acc: 0.9513 - val_loss: 0.1525 - val_acc: 0.9529\n",
      "Epoch 22/30\n",
      "106/106 [==============================] - 35s 307ms/step - loss: 0.1566 - acc: 0.9529 - val_loss: 0.1607 - val_acc: 0.9556\n",
      "Epoch 23/30\n",
      "106/106 [==============================] - 35s 308ms/step - loss: 0.1440 - acc: 0.9577 - val_loss: 0.1499 - val_acc: 0.9568\n",
      "Epoch 24/30\n",
      "106/106 [==============================] - 35s 306ms/step - loss: 0.1438 - acc: 0.9559 - val_loss: 0.1727 - val_acc: 0.9466\n",
      "Epoch 25/30\n",
      "106/106 [==============================] - 36s 313ms/step - loss: 0.1388 - acc: 0.9571 - val_loss: 0.1370 - val_acc: 0.9595\n",
      "Epoch 26/30\n",
      "106/106 [==============================] - 35s 312ms/step - loss: 0.1297 - acc: 0.9590 - val_loss: 0.1317 - val_acc: 0.9622\n",
      "Epoch 27/30\n",
      "106/106 [==============================] - 35s 310ms/step - loss: 0.1321 - acc: 0.9600 - val_loss: 0.1352 - val_acc: 0.9586\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 36s 314ms/step - loss: 0.1255 - acc: 0.9618 - val_loss: 0.1275 - val_acc: 0.9637\n",
      "Epoch 29/30\n",
      "106/106 [==============================] - 35s 312ms/step - loss: 0.1296 - acc: 0.9599 - val_loss: 0.1342 - val_acc: 0.9595\n",
      "Epoch 30/30\n",
      "106/106 [==============================] - 35s 312ms/step - loss: 0.1298 - acc: 0.9574 - val_loss: 0.1368 - val_acc: 0.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f60873f70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_maker()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_acc', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(train_generator, \n",
    "          epochs=NUM_EPOCHS, \n",
    "          validation_data=validation_generator, \n",
    "          validation_steps=len(validation_generator), \n",
    "          steps_per_epoch=len(train_generator), \n",
    "          verbose=1,\n",
    "          workers=num_cores,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNED_MODEL = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16882 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "# Извлекаю признаки\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "generator = datagen.flow_from_directory('augmented_data',\n",
    "                                        target_size=(224, 224),\n",
    "                                        class_mode=None,\n",
    "                                        shuffle=False)\n",
    "\n",
    "start_time = time.time()\n",
    "feature_list = []\n",
    "feature_list = TUNED_MODEL.predict(generator, NUM_EPOCHS)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images   =  16882\n",
      "Shape of feature_list =  (16882, 101)\n",
      "Time taken in sec =  29.39704179763794\n"
     ]
    }
   ],
   "source": [
    "for i, features in enumerate(feature_list):\n",
    "    feature_list[i] = features / norm(features)\n",
    "\n",
    "feature_list = feature_list.reshape(len(feature_list), -1)\n",
    "\n",
    "print(\"Num images   = \", len(generator.classes))\n",
    "print(\"Shape of feature_list = \", feature_list.shape)\n",
    "print(\"Time taken in sec = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['augmented_data' + '/' + s for s in generator.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(generator.classes, open('./data/tuned_class_ids-caltech101.pickle',\n",
    "                                    'wb'))\n",
    "pickle.dump(filenames, open('./data/tuned_filenames-caltech101.pickle', 'wb'))\n",
    "pickle.dump(\n",
    "    feature_list,\n",
    "    open('./data/tuned_features-caltech101-' + TUNED_MODEL.name + '.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my\\DL\\CV\\chapter-2\\.conda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая точность классификации: 99.26%\n",
      "\tairplanes: 98.73%\n",
      "\tbutterfly: 98.31%\n",
      "\telectric_guitar: 97.78%\n",
      "\tcrayfish: 97.67%\n",
      "\tlotus: 97.14%\n",
      "\tcannon: 96.77%\n",
      "\tketch: 96.43%\n",
      "\tschooner: 96.15%\n",
      "\tsunflower: 95.00%\n",
      "\tcougar_face: 94.87%\n",
      "\tbuddha: 94.74%\n",
      "\tmenorah: 94.74%\n",
      "\tanchor: 94.44%\n",
      "\tdragonfly: 94.44%\n",
      "\tkangaroo: 94.12%\n",
      "\tcrab: 92.86%\n",
      "\tcrocodile_head: 91.30%\n",
      "\tpagoda: 90.00%\n",
      "\theadphone: 87.50%\n",
      "\tcamera: 80.00%\n",
      "\tgarfield: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Сравнение\n",
    "new_list = get_classes(\n",
    "'augmented_data',\n",
    "'./data/tuned_filenames-caltech101.pickle',\n",
    "'./data/tuned_features-caltech101-' + TUNED_MODEL.name + '.pickle',\n",
    "'./data/tuned_class_ids-caltech101.pickle',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
